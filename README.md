# Deep Dive into AI with MLX and PyTorch
![cover.png](images/cover.png)
"Deep Dive into AI with MLX and PyTorch" is an educational initiative designed to help anyone interested in AI, specifically in machine learning and deep learning, using Apple's MLX and Meta's PyTorch frameworks.

Here's full disclosure how I work on this project with my AI buddies and family: 

[Full-Disclosure-Again-The-Synergy-Behind-The-Deep-Dive-Series-Books-With-AIs](essays/AI/Full-Disclosure-Again-The-Synergy-Behind-The-Deep-Dive-Series-Books-With-AIs.md)

## Main Sections

📓️ [First Book](book) | 📓️ [Second Book](mlx-book) | 📓️ [Third Book](math-book)
🤿 [Deep Dives](deep-dives) | [Concept Nuggets](concept-nuggets) | 📕  [Sidebars](book/sidebars) | ✍️ [Essays](essays) | 🗂️ [Resources](resources)

The first book is a comprehensive guide to AI using PyTorch and MLX, while the second book is dedicated to MLX.

The third book focuses on math, AI, and the path to enlightenment.

## What's New?

🔗 My New Website for AI Artworks and Essays: https://creativeworksofknowledge.net

Caution: I will be migrating my essays to my new website, where I will also continue to compose new ones, taking into account the recommended storage limit per repository on GitHub.

🔗 You can access this repo via my official domain: https://cwkai.net


🥠 [Concept Nuggets 002 - Understanding Transformers Through the Elden Ring Experience](concept-nuggets/002-transformers/README.md)

🥠 [Concept Nuggets 001 - Understanding Diffusion Transformers Through the Dark Souls Experience](concept-nuggets/001-diffusion-transformers/README.md)

🤿 Deep Dive 18: [Deep Dive in Diffusion Transformers](deep-dives/018-diffusion-transformer%2FREADME.md)

🤿 Deep Dive 17: [Deep Dive in Google's Gemini 1.5](deep-dives/017-google-gemini-1-point-5/README.md)

🤿 Deep Dive 16: [Deep Dive in OpenAI's Sora](deep-dives/016-openai-sora/README.md)

🤿 Deep Dive 15:  [Deep Dive in Meta AI's JEPA](deep-dives/015-meta-jepa/README.md)

🤿 Deep Dive 14: [Deep Dive into MetaAI MAGNeT](deep-dives/014-meta-ai-magnet/README.md)

<details>
<summary> Previous Additions </summary>

🤿 Deep Dive 13: [Deep Dive into RunwayML Gen-1](deep-dives/013-runwayml-gen1/README.md)

🤿 Deep Dive 12: [Deep Dive into Stability AI's Generative Models - Stable Audio](deep-dives/012-stable-audio/README.md)

🤿 Deep Dive 11: [Deep Dive into Stability AI's Generative Models - Stable Zero123](deep-dives/011-stable-zero123/README.md)

🤿 Deep Dive 10: [Deep Dive into Stability AI's Generative Models - Stable Video Diffusion](deep-dives/010-stable-video-diffusion/README.md)

✍️ New Essay: [Charting the Future of Careers Amidst AI](essays/life/Charting-The-Future-Of-Careers-Amidst-AI.md)

🤿 Deep Dive 9: [Deep Dive into Stability AI's Generative Models - SDXL Turbo](deep-dives/009-sdxl-turbo-add/README.md)

🎉 As of February 9, 2024, I have finished writing the third book on math, AI, and the path to enlightenment.
[Decoding the Universe: Math, AI, and the Path to Enlightenment](math-book/README.md)

✍️ [Chapter 11. Calculus - Navigating the Dynamics of Change](math-book/011-calculus-navigating-the-dynamics-of-change/README.md)

✍️ [Chapter 10. Statistics Part III - The Art of Learning from Data](math-book/010-stats-part3-the-art-of-learning-from-data/README.md)

✍️ [Chapter 9. Statistics Part II - The Enchantment of Normality](math-book/009-stats-part2-the-enchantment-of-normality/README.md)

✍️ [Chapter 8. Statistics Part I - The Art of Insightful Guesswork](math-book/008-stats-part1-the-art-of-insightful-guesswork/README.md)

✍️ [Chapter 7. Logarithms - The Ultimate Normalizer](math-book/007-logarithms-the-ultimate-normalizer/README.md)

✍️ [Chapter 6. Linear Algebra Part III - Eigenvalues and Eigenvectors: The Heartbeat of Matrices](math-book/006-linear-algebra-part3-eigenvalues-and-eigenvectors-the-heartbeat-of-matrices/README.md)

✍️ [Chapter 5. Linear Algebra Part II - Matrices: Gateways to Multidimensional Magic](math-book/005-linear-algebra-part2-matrices-gateways-to-multidimensional-magic/README.md)

✍️ [Chapter 4. Linear Algebra Part I - Casting Multidimensional Magic](math-book/004-linear-algebra-part1-casting-multidimensional-magic/README.md)

✍️ [Chapter 3: Taming the Infinite – The Art of Number Management](math-book/003-taming-the-infinite-the-art-of-number-management/README.md)

✍️ [Chapter 2. The Necessity of Higher Dimensions - From Simple Cats to Cat Women](math-book/002-the-necessity-of-higher-dimensions/README.md)

✍️ [Chapter 1. A High Dimensional Universe - Rethinking What You Experience](math-book/001-a-high-dimensional-universe-rethinking-what-you-experience/README.md)

✍️ Started writing my 3rd book: [Decoding the Universe: Math, AI, and the Path to Enlightenment ](math-book/000-prologue/README.md)

🤿 Deep Dive 8: [Deep Dive into Stability AI's Generative Models - Stable Diffusion XL](deep-dives/008-stable-diffusion-sdxl/README.md)

🤿 Deep Dive 7: [Deep Dive into Prompt Engineering to Harness the True Power of Large Language Models](deep-dives/007-prompt-engineering-to-harness-the-true-power-of-large-language-models/README.md)

🤿 Deep Dive 6: [Deep Dive into LLaVA](deep-dives/006-llava/README.md)

🤿 Deep Dive 5: [Deep Dive into CLIP](deep-dives/005-CLIP/README.md)

🤿 Deep Dive 4: [Deep Dive into RWKV Language Model - Eagle 7B](deep-dives/004-rwkv-eagle-7b/README.md)

✍️ New Essay under "Investing": [Maximizing-Open-Source-Benefits](essays/investing/Maximizing-Open-Source-Benefits.md)

🆕 MLX Appendix: v0.1.0 - [Gradient-Checkpoint](mlx-book/appendix/gradient-checkpoint/Gradient-Checkpoint.md)

🤿 Deep Dive 3: [Deep Dive into Audio Processing and the Whisper Model](deep-dives/003-whisper/README.md)

✍️ New Essay: [Trading-Health-For-Aesthetics-And-Cheapness](essays/computing/Trading-Health-For-Aesthetics-And-Cheapness.md)

📝 New Sidebar: [Model-Parameters-And-Vram-Requirements-Can-My-Gpu-Handle-It](book/sidebars/model-parameters-and-vram-requirements-can-my-gpu-handle-it/Model-Parameters-And-Vram-Requirements-Can-My-Gpu-Handle-It.md)

🤿 Deep Dive 2: [Deep Dive into Mixtral 8x7B](deep-dives/002-mixtral-8x7b/README.md)

🤿 Deep Dive 1: [Deep Dive into Mistral 7B](deep-dives/001-mistral-7b/README.md)

👉 The Deep Dives Section Added: [Deep Dives](deep-dives/README.md)

👉 Some of you asked how: [Embracing-Speed-And-Efficiency-My-Fast-And-Furious-Methodology](essays/life/Embracing-Speed-And-Efficiency-My-Fast-And-Furious-Methodology.md)

🎉 As of January 29, 2024, I have finished writing the second book on MLX, but I'll keep updating it as necessary.

https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/tree/master/mlx-book/README.md

🎉 As of January 24, 2024, I have finished writing the book on both MLX and PyTorch, but I'll keep updating it as necessary.

https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/blob/master/book/README.md

</details>

## Project Overview

The best way to grasp any concept is to articulate it in your own words, an approach I've actively practiced throughout my life. Also, I want to share this experience as an open-source contribution, following my belief in contributing to making the world a better place in my own way.

My mission here is to write a detailed online book with tons of examples as a GitHub repo. Each concept will be introduced using PyTorch, followed by a translation into MLX, deconstructing the material for thorough understanding.

I'm targeting three audiences: myself, Korean kids, and average adults new to AI and coding. I'll go into detail when needed. I'll also use simple English to help non-native speakers understand. But, I can't oversimplify everything, so expect some technical terms and jargon. I'll do my best to explain them. If there's something you don't get, try looking it up first before asking.

Everything, including the code and comments, will be in English. A good command of English is essential for understanding the code. It's an uncomfortable truth, but it's necessary. (To my fellow Koreans: Believe me, as someone who has been a lifelong resident and has learned everything in English throughout my life, I can confidently say that if I can do it, so can you. It's not just beneficial—it's crucial.)

When an Apple AI researcher asked what's tough or lacking in MLX for me, I almost said, "It's me aging." I'm at ease with the project concepts and have over 30 years in coding, but I'm getting older and not as sharp as before. So, I'm writing this book as if it's for me. Please bear with me.

Even with getting older, trust me, I'm still fast. So no dragging your feet. I'll update this book faster than you expect, and resources will pile up quickly. If you want to keep up, don't delay.

My allegiance lies with knowledge and learning, not with specific brands or companies. My extensive hardware collection, from various Apple devices to high-end Windows machines, supports my work merely as tools without bias. As an investor, I apply critical thinking indiscriminately.

So, please, don't label me as a fanboy of anything.

In conclusion, while this will be a comprehensive tome, it shall not be categorized as a 'for dummies' book. Don't remain clueless; make an effort to learn. I'll do everything I can to assist you. 

## Rationale for MLX and PyTorch

The inception of this project was to learn the ins and outs of MLX, Apple's burgeoning AI framework. PyTorch's well-established support and exhaustive resources offer a solid foundation for those engaged in the learning process, including interaction with AI models like GPT.

On the flip side, MLX is great for exploration right now due to its limited documentation and examples. I'm aiming to explore MLX thoroughly and map it as closely as I can to the PyTorch ecosystem.

Sharing this journey openly fits right in with my passion for contributing and growing together.

## Why Not TensorFlow?

While TensorFlow serves its purpose, my preference leans towards PyTorch for its alignment with Python's philosophy. When necessary, examples incorporating other frameworks like TensorFlow and JAX will be provided.

## The Case Against Notebooks

Ju