# GPT vs. GPT - Hell of Confusion

![hell-of-confusion.png](images%2Fhell-of-confusion.png)

What's intriguing about the pursuit of knowledge is that confusion can often pave the way to genuine insight – take this instance for example. Go on and quiz your AI model about the distinctions between wide and long data formats in data science and in Pandas.

Provide it with examples of each format and request an explanation of the distinctions. You could use images of Excel spreadsheets or CSV files. Given these visuals, GPT-4 should be able to discern the differences between the formats and dispel the confusion. Or so one might think. Yet, repeatedly, it manages to muddle up the terms 'wide' and 'long' in its explanations. Essentially, it knows the formats but trips over the terminology. Probe it on these terms specifically within the realms of data science, machine learning, and with examples from Pandas code. Welcome to the labyrinth of confusion.

I've played around with two instances of the GPT-4 models only to find they offer up contradictory information. Set them to interact, and they spiral into a loop of uncertainty. At first, they spit out the same answers, but as the conversation progresses, they begin to contradict each other.

The responses might surprise you. It's important to maintain the back-and-forth and to scrutinize their responses personally.

In the midst of this chaos, you're likely to stumble upon insights that direct you to the correct answers. Trust me on this – the initial sense of being overwhelmed by confusion gradually morphs into a golden chance for learning. You enhance your grasp to the point where you can dissipate the fog of confusion yourself. And when you lay it out for GPT, it agrees. You emerge from the maelstrom of confusion with a robust piece of knowledge to inherit and develop further.

Adding a final thought – since AI models learn from us across a wide array of topics, they are prone to mirroring our errors. I've noticed numerous spelling mistakes in AI-generated texts, which is ironic, isn't it? They're machines! But somehow, they replicate our own common typos. Ponder the implications of that.